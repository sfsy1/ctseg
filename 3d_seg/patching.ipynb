{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Splitting volumes into patches\n",
    "* create patches around lesions\n",
    "* create sliding windows patches\n",
    "  * keep the ones with lesion voxels\n",
    "* get xyz ranges of patches\n",
    "* use ranges to crop other channels\n",
    "* save patches\n",
    "* save ranges in filenames or in pickles to crop more channels in the future"
   ],
   "id": "98b2a37142e68fb3"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-09T15:10:33.687445Z",
     "start_time": "2025-04-09T15:10:33.685676Z"
    }
   },
   "source": [
    "import math\n",
    "from pathlib import Path\n",
    "\n",
    "import SimpleITK as sitk\n",
    "import cc3d\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "data_folder = Path(\"/media/liushifeng/KINGSTON/nnUNet_raw/Dataset001_3dlesion\")\n",
    "train_images = data_folder / \"imagesTr\"\n",
    "train_labels = data_folder / \"labelsTr\""
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# constants\n",
    "PATCH_SIZE_MM = (64, 128, 128)  # zyx\n",
    "PATCH_DIMS = (24, 128, 128)  # zyx"
   ],
   "id": "5a5ee0a6a695d4fe",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def get_centroid(coords):\n",
    "    return np.mean(coords, axis=0).round().astype(int)\n",
    "\n",
    "\n",
    "def sample_points(coords):\n",
    "    centroid = get_centroid(coords)\n",
    "    coords = np.vstack([c for c in coords if np.any(c != centroid)])\n",
    "    n_points = 2\n",
    "    point_indices = np.random.choice(len(coords), n_points, replace=False)\n",
    "    sampled_points = np.vstack([coords[point_indices], centroid]).astype(int)\n",
    "    return np.unique(sampled_points, axis=0)\n",
    "\n",
    "\n",
    "def get_xyz_range(point, spacing, patch_size_mm):\n",
    "    x_size = round(patch_size_mm[2] / spacing[0])\n",
    "    y_size = round(patch_size_mm[1] / spacing[1])\n",
    "    z_size = round(patch_size_mm[0] / spacing[2])\n",
    "\n",
    "    x_start = point[2] - x_size // 2\n",
    "    x_end = x_start + x_size\n",
    "    y_start = point[1] - y_size // 2\n",
    "    y_end = y_start + y_size\n",
    "    z_start = point[0] - z_size // 2\n",
    "    z_end = z_start + z_size\n",
    "    return (x_start, x_end), (y_start, y_end), (z_start, z_end)\n",
    "\n",
    "\n",
    "def calculate_padding(array, x_range, y_range, z_range):\n",
    "    # array is zyx\n",
    "    pad_x = (max(-x_range[0], 0), max(x_range[1] - array.shape[2], 0))\n",
    "    pad_y = (max(-y_range[0], 0), max(y_range[1] - array.shape[1], 0))\n",
    "    pad_z = (max(-z_range[0], 0), max(z_range[1] - array.shape[0], 0))\n",
    "    return pad_x, pad_y, pad_z\n",
    "\n",
    "\n",
    "def resize_volume(volume, new_shape):\n",
    "    tensor = torch.from_numpy(volume).unsqueeze(0).unsqueeze(0).float()\n",
    "    resized_tensor = F.interpolate(tensor, size=new_shape, mode='trilinear')\n",
    "    return resized_tensor.squeeze().numpy()\n",
    "\n",
    "\n",
    "def get_patch(array, point, spacing, patch_dims=PATCH_DIMS, patch_size_mm=PATCH_SIZE_MM):\n",
    "    # get ranges to crop\n",
    "    x_range, y_range, z_range = get_xyz_range(point, spacing, patch_size_mm)\n",
    "\n",
    "    # pad array so it fits within the range\n",
    "    pad_x, pad_y, pad_z = calculate_padding(array, x_range, y_range, z_range)\n",
    "    array_padded = np.pad(array, (pad_z, pad_y, pad_x), mode='reflect')  # mode='constant', constant_values=pad_value\n",
    "\n",
    "    # adjust range after padding\n",
    "    z_range = [z + pad_z[0] for z in z_range]\n",
    "    y_range = [y + pad_y[0] for y in y_range]\n",
    "    x_range = [x + pad_x[0] for x in x_range]\n",
    "\n",
    "    # crop and resize\n",
    "    patch = array_padded[z_range[0]:z_range[1], y_range[0]:y_range[1], x_range[0]:x_range[1]]\n",
    "    return resize_volume(patch, patch_dims)"
   ],
   "id": "94e02aadcefc3eea",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# f = random.sample(uls_img, 1)[0]\n",
    "f = \"AutoPET-Lymphoma-B_PETCT_0fa313309d_CT_0000.nii.gz\"\n",
    "# f = \"ULSDL3D_000441_02_01_187_lesion_01_0000.nii.gz\"\n",
    "\n",
    "# load CT and seg\n",
    "ct_path = train_images / f\n",
    "ct_img = sitk.ReadImage(ct_path)\n",
    "ct_data = sitk.GetArrayFromImage(ct_img)\n",
    "\n",
    "seg_path = train_labels / f.replace(\"_0000.nii.gz\", \".nii.gz\")\n",
    "seg_img = sitk.ReadImage(seg_path)\n",
    "seg_data = sitk.GetArrayFromImage(seg_img)\n",
    "spacing = seg_img.GetSpacing()\n",
    "\n",
    "# get connected components in seg\n",
    "labels, n_components = cc3d.connected_components(seg_data, return_N=True)\n",
    "n_components"
   ],
   "id": "285fef9444a4fbab",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# get centroid patches\n",
    "seg_patches = []\n",
    "ct_patches = []\n",
    "for c in range(1, n_components + 1):\n",
    "    coords = np.argwhere(labels == c)\n",
    "    point = get_centroid(coords)\n",
    "\n",
    "    seg_patches.append(get_patch(seg_data, point, spacing))\n",
    "    ct_patches.append(get_patch(ct_data, point, spacing))"
   ],
   "id": "fd3311883f8016ed",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Seg",
   "id": "672bda624e916d6b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-09T15:10:41.287833Z",
     "start_time": "2025-04-09T15:10:38.134990Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from lighter_zoo import SegResNet\n",
    "from monai.inferers import SlidingWindowInferer\n",
    "from monai.transforms import (\n",
    "    Compose, LoadImage, Orientation,\n",
    "    ScaleIntensityRange, Activations, AsDiscrete, KeepLargestConnectedComponent\n",
    ")\n",
    "device = \"cuda\"\n",
    "seg_model = SegResNet.from_pretrained(\n",
    "    \"project-lighter/whole_body_segmentation\",\n",
    ").to(device)\n",
    "\n",
    "seg_preprocess = Compose([\n",
    "    LoadImage(ensure_channel_first=True),  # Load image and ensure channel dimension\n",
    "    Orientation(axcodes=\"SPL\"),  # Standardize orientation\n",
    "])\n",
    "\n",
    "ct_preprocess = Compose([\n",
    "    LoadImage(ensure_channel_first=True),  # Load image and ensure channel dimension\n",
    "    Orientation(axcodes=\"SPL\"),  # Standardize orientation\n",
    "    ScaleIntensityRange(\n",
    "        a_min=-1024,  # Min HU value\n",
    "        a_max=2048,  # Max HU value\n",
    "        b_min=0,  # Target min\n",
    "        b_max=1,  # Target max\n",
    "        clip=True  # Clip values outside range\n",
    "    ),\n",
    "])\n",
    "\n",
    "postprocess = Compose([\n",
    "    Activations(softmax=True),\n",
    "    AsDiscrete(argmax=True, to_onehot=118),  # threshold=0.1, dtype=torch.int16\n",
    "    KeepLargestConnectedComponent(),\n",
    "    # Invert(transform=ct_preprocess),           # Restore original space\n",
    "    # SaveImage(output_dir=\"./ct_fm_output\")\n",
    "])\n",
    "\n",
    "# create sliding window patches\n",
    "inferer = SlidingWindowInferer(\n",
    "    roi_size=[96, 160, 160],\n",
    "    sw_batch_size=1,\n",
    "    overlap=0.5,\n",
    "    mode=\"gaussian\",\n",
    "    device='cpu',\n",
    "    sw_device=device,\n",
    ")"
   ],
   "id": "b9b885e2cec4554d",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-09T15:10:49.930659Z",
     "start_time": "2025-04-09T15:10:46.714669Z"
    }
   },
   "cell_type": "code",
   "source": [
    "seg = seg_preprocess(seg_path)\n",
    "ct = ct_preprocess(ct_path)"
   ],
   "id": "109a562c8257c183",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def get_n_windows(x, width, overlap):\n",
    "    \"\"\"Get number of windows that can fit, and remainder as a ratio of window\"\"\"\n",
    "    windows = (x - overlap) / (width - overlap)\n",
    "    remainder = windows % 1 * (width - overlap) / width\n",
    "    return math.floor(windows), remainder\n",
    "\n",
    "\n",
    "def get_step_size(x, width, n) -> int:\n",
    "    \"\"\"Calculate step size needed to fit n windows in x\"\"\"\n",
    "    if n == 1:\n",
    "        return 0\n",
    "    overlap = (n * width - x) / (n - 1)\n",
    "    return width - overlap\n",
    "\n",
    "\n",
    "def get_range(dim, x, width, step) -> tuple:\n",
    "    \"\"\"get start and end range of a dimension given window width and step\"\"\"\n",
    "    start = round(x * step)\n",
    "    end = start + width\n",
    "    if end > dim:  # if it exceeds the dimension\n",
    "        end = dim\n",
    "        start = end - width\n",
    "    return start, end\n",
    "\n",
    "def generate_patches(volume, patch_size, overlap_ratio=0.5):\n",
    "    \"\"\"Generate sliding windows\"\"\"\n",
    "    shape = list(volume.shape)  # zyx\n",
    "\n",
    "    prelim_overlaps = [overlap_ratio * x for x in patch_size]\n",
    "    n_windows = [get_n_windows(x, w, s)[0] for x, w, s in zip(shape, patch_size, prelim_overlaps)]\n",
    "    remainders = [get_n_windows(x, w, s)[1] for x, w, s in zip(shape, patch_size, prelim_overlaps)]\n",
    "\n",
    "    # add an extra window if there's remainder >10% of window\n",
    "    n_windows = [(n + 1 if r > 0.1 else n) for n, r in zip(n_windows, remainders)]\n",
    "\n",
    "    # calculate new step size to evenly distribute the windows\n",
    "    steps = [get_step_size(x, w, n) for x, w, n in zip(shape, patch_size, n_windows)]\n",
    "\n",
    "    print(\"winds\", n_windows)\n",
    "    print(\"steps\", steps)\n",
    "\n",
    "    patches = []\n",
    "    for z in range(n_windows[0]):\n",
    "        z_start, z_end = get_range(shape[0], z, patch_size[0], steps[0])\n",
    "        for y in range(n_windows[1]):\n",
    "            y_start, y_end = get_range(shape[1], y, patch_size[1], steps[1])\n",
    "            for x in range(n_windows[2]):\n",
    "                x_start, x_end = get_range(shape[2], x, patch_size[2], steps[2])\n",
    "                patches.append(volume[z_start:z_end, y_start:y_end, x_start:x_end])\n",
    "    return patches"
   ],
   "id": "2a74df3ade2e2f78",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "patch_size = [64, 128, 128]\n",
    "overlap_ratio = 0.5\n",
    "\n",
    "ct_patches = generate_patches(ct[0], patch_size, overlap_ratio)\n",
    "# seg_patches = generate_patches(seg[0])"
   ],
   "id": "38d92b6a6ca0a44a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from utils.plot import transparent_cmap\n",
    "\n",
    "n = 373\n",
    "\n",
    "for i in range(len(ct_patches)):\n",
    "    print(i)\n",
    "    fig, axes = plt.subplots(1, 2)\n",
    "    axes[0].imshow(ct_patches[n][i], cmap=\"gray\")\n",
    "    axes[1].imshow(ct_patches[n][i], cmap=\"gray\")\n",
    "    axes[1].imshow(seg_patches[n][i], cmap=transparent_cmap(\"r\"), alpha=0.5)\n",
    "    plt.show()"
   ],
   "id": "9fb8743f9fd3badf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "out_raw = inferer(ct_patches[373].unsqueeze(0).unsqueeze(0), seg_model)  # seg_model)  # lambda x: x)",
   "id": "29c7c632ea71e9fe",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "out = postprocess(out_raw)[0]",
   "id": "61e99a19b9fe0654",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "out.shape",
   "id": "b1e0fe3994789665",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "plt.imshow(out[], vmin=0, vmax=117, cmap=\"gist_stern\")",
   "id": "3cd70c17940a685a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "plt.imshow(out.detach().numpy())",
   "id": "9597ca29f163d9b4",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

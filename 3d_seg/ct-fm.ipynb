{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Fine Tune CT-FM 3D Segmentation Model\n",
    "Use ULS DeepLesion 3D (700+ samples)\n",
    "* Split data into patches of 12.8cm x 12.8cm x 6.4cm, based on `Spacing_mm_px_` in DL_info.csv\n",
    "* Encode using CT-FM\n",
    "* Decode into segmentation mask of middle slice"
   ],
   "id": "81131a23a370aada"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Test Inference",
   "id": "b9f10822d7df6cf5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "import random\n",
    "from pathlib import Path\n",
    "import SimpleITK as sitk\n",
    "\n",
    "# load data from 3D dataset for nnUNet\n",
    "data_folder = Path(\"/media/liushifeng/KINGSTON/nnUNet_raw/Dataset001_3dlesion\")\n",
    "train_images = data_folder / \"imagesTr\"\n",
    "train_labels = data_folder / \"labelsTr\"\n",
    "\n",
    "uls_img = [x for x in os.listdir(train_images) if x.startswith(\"ULS\")]\n",
    "ap_img = [x for x in os.listdir(train_images) if x.startswith(\"AutoPET\")]\n",
    "f = uls_img[0]\n",
    "print(f)\n",
    "\n",
    "# Load data\n",
    "ct_path = train_images / f\n",
    "seg_path = train_labels / f.replace(\"_0000.nii.gz\", \".nii.gz\")\n",
    "# seg_data = sitk.GetArrayFromImage(sitk.ReadImage(seg_path))\n",
    "# ct_data = sitk.GetArrayFromImage(sitk.ReadImage(ct_path))"
   ],
   "id": "7c5ed0ab85945e49",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from lighter_zoo import SegResNet\n",
    "from monai.transforms import LoadImage\n",
    "from setup_utils import get_inferer, get_preprocess, get_postprocess\n",
    "\n",
    "# load model\n",
    "model_name = \"project-lighter/whole_body_segmentation\"\n",
    "device = \"cuda\"\n",
    "seg_model = SegResNet.from_pretrained(model_name).to(device)\n",
    "\n",
    "# load pipelines\n",
    "inferer = get_inferer(device)\n",
    "preprocess = get_preprocess()\n",
    "postprocess = get_postprocess(preprocess)"
   ],
   "id": "6377c4898c9ab7ac",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "input_tensor = preprocess(ct_path)\n",
    "with torch.no_grad():\n",
    "    output = inferer(input_tensor.unsqueeze(dim=0), seg_model.to(device))[0]\n",
    "    print(f\"{output.shape=}\")\n",
    "\n",
    "output.applied_operations = input_tensor.applied_operations\n",
    "output.affine = input_tensor.affine\n",
    "result = postprocess(output[0])\n",
    "print(result.shape)"
   ],
   "id": "317ab812475f826f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# load scan to visualize with masks\n",
    "ct_img = LoadImage()(ct_path)"
   ],
   "id": "ed0a08ba1e6ed7d9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# visualize\n",
    "res = result.squeeze()\n",
    "for i in range(0, res.shape[-1], 2):\n",
    "    seg_mask = res[..., i].rot90()\n",
    "    if (seg_mask > 0).sum() > 0:\n",
    "        ct_slice = ct_img[:, :, i].rot90()\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(6, 3))\n",
    "        axes[0].imshow(ct_slice, cmap=\"gray\")\n",
    "        axes[1].imshow(seg_mask, vmin=0, vmax=117, cmap=\"gist_stern\")\n",
    "        plt.show()\n",
    "        break\n"
   ],
   "id": "ef1cd4a317412d02",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Fine-tune seg model",
   "id": "24f3a264d679f76c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from torch.nn import Conv3d\n",
    "import numpy as np\n",
    "import cc3d\n",
    "from utils.plot import transparent_cmap"
   ],
   "id": "61ba2d56334c740c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# replace head to single channel conv\n",
    "seg_model.up_layers[3].head = Conv3d(32, 1, kernel_size=(1, 1, 1), stride=(1, 1, 1))"
   ],
   "id": "237f27f4b6545d0b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Data processing",
   "id": "ea986eb8b2afc032"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# select sample\n",
    "from patching import sample_points, get_lesion_patch\n",
    "import random\n",
    "f = random.sample(uls_img, 1)[0]\n",
    "# f = \"AutoPET-Lymphoma-B_PETCT_0fa313309d_CT_0000.nii.gz\"\n",
    "f = \"ULSDL3D_000441_02_01_187_lesion_01_0000.nii.gz\"\n",
    "\n",
    "# load CT and seg\n",
    "ct_path = train_images / f\n",
    "ct_img = sitk.ReadImage(ct_path)\n",
    "ct_data = sitk.GetArrayFromImage(ct_img)\n",
    "\n",
    "seg_path = train_labels / f.replace(\"_0000.nii.gz\", \".nii.gz\")\n",
    "seg_img = sitk.ReadImage(seg_path)\n",
    "seg_data = sitk.GetArrayFromImage(seg_img)\n",
    "spacing = seg_img.GetSpacing()\n",
    "\n",
    "# get connected components in seg\n",
    "labels, n_components = cc3d.connected_components(seg_data, return_N=True)\n",
    "\n",
    "# sample points within cc\n",
    "for c in range(1, n_components + 1):\n",
    "    coords = np.argwhere(labels == c)\n",
    "    points = sample_points(coords)\n",
    "    for point in points:\n",
    "        # crop volume around the point\n",
    "        seg_patch = get_lesion_patch(seg_data, point, spacing)\n",
    "        ct_patch = get_lesion_patch(ct_data, point, spacing)\n",
    "        print(f\"{f[:10]} {c=} {point=}\")"
   ],
   "id": "cd22546babaaa5a0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "93e225c903543973",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

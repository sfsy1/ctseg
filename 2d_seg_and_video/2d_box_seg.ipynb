{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Training a 2D bbox to 2D segmentation model\n",
    "---"
   ],
   "id": "7acbf8c49883ba50"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from collections import Counter\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from evaluation.eval_utils import get_seg_bbox\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "import nrrd\n",
    "import SimpleITK as sitk\n",
    "from utils.plot import transparent_cmap\n",
    "\n",
    "# Dataset\n",
    "data_folder = Path(\"/media/liushifeng/KINGSTON/ULS Jan 2025/ULS23/novel_data/ULS23_DeepLesion3D\")\n",
    "seg_folder = data_folder / \"labels\"\n",
    "ct_folder = data_folder / \"images\"\n",
    "\n",
    "with open(data_folder / \"train.txt\", \"r\") as f:\n",
    "    train_names = [x.strip() for x in f.readlines()]\n",
    "with open(data_folder / \"val.txt\", \"r\") as f:\n",
    "    val_names = [x.strip() for x in f.readlines()]\n",
    "\n",
    "filenames = [x for x in os.listdir(seg_folder) if \".zip\" not in x]\n",
    "seg_paths = {x: seg_folder / x for x in filenames}\n",
    "ct_paths = {x: ct_folder / x for x in filenames}"
   ],
   "id": "6c8827d5c971ef1f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "ignored_train_samples = [x.strip() for x in\n",
    "    \"\"\"\n",
    "    000148_04_01_034_lesion_01\n",
    "    003287_01_01_188_lesion_01\n",
    "    003931_01_01_078_lesion_01\n",
    "    000026_06_01_257_lesion_01\n",
    "    000346_01_01_085_lesion_01\n",
    "    000215_05_01_096_lesion_01\n",
    "    001354_04_02_305_lesion_01\n",
    "    001564_02_02_513_lesion_01\n",
    "    \"\"\".split(\"\\n\") if x.strip()]"
   ],
   "id": "cd4a56b7eb04c589",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# for plotting histograms\n",
    "bins = [int(x) for x in np.arange(-1000, 2001, 50)] + [2050] # Define HU bins\n",
    "hu_counter = Counter()  # Initialize the counter"
   ],
   "id": "fbc15bc7479b24ae",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "for every lesion, based on filename:\n",
    "- input\n",
    "    - crop (32X * 32Y)\n",
    "    - rectangle patch or border of the segment (32X * 32Y)\n",
    "    - full slice as context (fixed size e.g. 256 * 256)\n",
    "- output\n",
    "    - seg (32X * 32Y) **Blur for soft mask?**"
   ],
   "id": "6872350c925448ec"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "seg, _ = nrrd.read(\"/media/liushifeng/KINGSTON/ULS DL3D 2D dataset/masks/002779_01_01_183_lesion_01_slice61_seg\")",
   "id": "c47efa74517ceef7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from train_utils import crop_from_img\n",
    "\n",
    "output_folder = Path(\"/media/liushifeng/KINGSTON/ULS DL3D 2D dataset/\")\n",
    "\n",
    "plot = 0\n",
    "save = 0\n",
    "\n",
    "for filename in list(seg_paths.keys()):\n",
    "    if filename.split(\".\")[0] in ignored_train_samples:\n",
    "        print(\"skipped:\", filename.split(\".\")[0])\n",
    "        continue\n",
    "\n",
    "    lesion_name = filename.split(\".\")[0]\n",
    "\n",
    "    # load arrays\n",
    "    ct = sitk.ReadImage(ct_paths[filename])\n",
    "    ct_array = sitk.GetArrayFromImage(ct)\n",
    "    seg = sitk.ReadImage(seg_paths[filename])\n",
    "    seg_array = sitk.GetArrayFromImage(seg)\n",
    "\n",
    "    # get slices where there are segmentations\n",
    "    seg_slice_indices = np.where(seg_array.any(axis=(1,2)) > 0)[0]\n",
    "\n",
    "    for i in seg_slice_indices:\n",
    "        ct_slice = ct_array[i]\n",
    "        seg_slice = seg_array[i]\n",
    "\n",
    "        crop_bbox = get_seg_bbox(seg_slice)\n",
    "\n",
    "        if save:\n",
    "            print(f\"saving {lesion_name}_slice{i}\")\n",
    "            # train_or_val = \"train\" if lesion_name in train_names else \"val\"\n",
    "            # save_folder = output_folder / train_or_val\n",
    "            # save_folder.mkdir(parents=True, exist_ok=True)\n",
    "            np.save(str(output_folder / \"images\" / f\"{lesion_name}_slice{i}.npy\"), ct_slice)\n",
    "            # nrrd.write(str(output_folder / \"slices\" / f\"{lesion_name}_slice{i}_seg\"), seg_slice)\n",
    "\n",
    "        if plot:\n",
    "            vmin, vmax = -200, 200\n",
    "            plt.imshow(ct_slice, vmin=vmin, vmax=vmax, cmap='gray')\n",
    "            plt.show()\n",
    "            plt.imshow(seg_slice)\n",
    "            plt.show()\n",
    "\n",
    "            # crops areas for plotting\n",
    "            margin = 2\n",
    "            ct_crop = crop_from_img(ct_slice, crop_bbox, margin, AIR_VALUE)\n",
    "            seg_crop = crop_from_img(seg_slice, crop_bbox, margin, 0)\n",
    "\n",
    "        # hu_counter.update(np.digitize(ct_crop.flatten(), bins))\n",
    "        # hu_counter.update(np.digitize(ct_crop[seg_crop == 1], bins))"
   ],
   "id": "a79388468058c798",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# plt.figure(figsize=(6,2.5));\n",
    "# plt.bar([bins[int(x)] for x in hu_counter.keys()], hu_counter.values(), width=50);\n",
    "#\n",
    "# plt.imshow(ct_slice, cmap='gray'); plt.axis(\"off\")\n",
    "# plt.imshow(seg_slice, cmap='jet', alpha=0.5); plt.axis(\"off\");"
   ],
   "id": "abe8c51a273ef04",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Load data",
   "id": "ca184f5857d77770"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "from torch.utils.data import DataLoader\n",
    "from dataset import SegmentationDataset\n",
    "from transforms import train_transform, val_transform, context_transform\n",
    "\n",
    "# data\n",
    "data_dir = Path(\"/media/liushifeng/KINGSTON/ULS DL3D 2D dataset\")\n",
    "image_dir = data_dir / \"images\"\n",
    "label_dir = data_dir / \"masks\"\n",
    "all_images = sorted(os.listdir(image_dir))\n",
    "\n",
    "val_images = [x for x in all_images if x.split(\"_slice\")[0] in val_names]\n",
    "train_images = [x for x in all_images if x.split(\"_slice\")[0] in train_names]\n",
    "\n",
    "# dataloaders\n",
    "image_names = None\n",
    "batch_size = 32\n",
    "workers = 24\n",
    "train_dataset = SegmentationDataset(\n",
    "    image_dir, label_dir, train_images, train_transform, context_transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=workers)\n",
    "\n",
    "val_dataset = SegmentationDataset(image_dir, label_dir, val_images, val_transform, context_transform)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True, num_workers=workers)"
   ],
   "id": "37f02184712b935d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Visualizing data loader\n",
    "data = next(iter(val_loader))\n",
    "plt.figure(figsize=(1.5,1.5))\n",
    "plt.imshow(data['image'][0].squeeze(), cmap='gray')\n",
    "plt.imshow(data['mask'][0].squeeze(), cmap=transparent_cmap(\"b\"), alpha=0.5)\n",
    "plt.imshow(data['box_mask'][0].squeeze(), vmin=0, vmax=1, cmap=transparent_cmap(\"g\"), alpha=0.3)\n",
    "# plt.axis('off');\n",
    "print(data['image'][0].shape)\n",
    "plt.show()"
   ],
   "id": "f005c29dd4e4cdf7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Train Model",
   "id": "956e15960762c2b5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from glob import glob\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=SyntaxWarning)\n",
    "import torch\n",
    "import lightning as L\n",
    "from lightning.pytorch.callbacks import EarlyStopping\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ],
   "id": "7a149f50f5d1f802",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from model import UNet\n",
    "\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=workers)\n",
    "\n",
    "# torch.set_float32_matmul_precision('medium')\n",
    "unet = UNet()\n",
    "unet = torch.compile(unet)\n",
    "early_stopping = EarlyStopping('val_loss', patience=5, verbose=True)\n",
    "logger = TensorBoardLogger(\"lightning_logs\", name=\"dl1\")  # name=\"my_model\", version=\"GAT\"\n",
    "trainer = L.Trainer(\n",
    "    max_epochs=70,\n",
    "    callbacks=[early_stopping],\n",
    "    logger=logger,\n",
    ")\n",
    "trainer.fit(unet, train_loader, val_loader)"
   ],
   "id": "18945fe911f91775",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "ckpt_path = glob(\"lightning_logs/dl3/version_1/*/*.ckpt\")[0]; print(ckpt_path)\n",
    "unet = UNet.load_from_checkpoint(ckpt_path)"
   ],
   "id": "7b0c84015386888",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "large_lesion_names = ['000083_07_01_114_lesion_01_slice56.npy',\n",
    " '000083_07_01_114_lesion_01_slice57.npy',\n",
    " '000083_07_01_114_lesion_01_slice58.npy',\n",
    " '000083_07_01_114_lesion_01_slice59.npy',\n",
    " '000083_07_01_114_lesion_01_slice60.npy',\n",
    " '000083_07_01_114_lesion_01_slice61.npy',\n",
    " '000083_07_01_114_lesion_01_slice62.npy',\n",
    " '000083_07_01_114_lesion_01_slice63.npy',\n",
    " '000083_07_01_114_lesion_01_slice64.npy',\n",
    " '000083_07_01_114_lesion_01_slice65.npy',\n",
    " '000083_07_01_114_lesion_01_slice66.npy',\n",
    " '000083_07_01_114_lesion_01_slice67.npy',\n",
    " '000083_07_01_114_lesion_01_slice68.npy',\n",
    " '000425_01_01_058_lesion_01_slice61.npy',\n",
    " '000425_01_01_058_lesion_01_slice62.npy',\n",
    " '000425_01_01_058_lesion_01_slice63.npy',\n",
    " '000425_01_01_058_lesion_01_slice64.npy',\n",
    " '000425_01_01_058_lesion_01_slice65.npy',\n",
    " '000425_01_01_058_lesion_01_slice66.npy',\n",
    " '000425_01_01_058_lesion_01_slice67.npy',\n",
    " '000482_02_01_099_lesion_01_slice62.npy',\n",
    " '000482_02_01_099_lesion_01_slice63.npy',\n",
    " '000482_02_01_099_lesion_01_slice64.npy',\n",
    " '000482_02_01_099_lesion_01_slice65.npy',\n",
    " '000482_02_01_099_lesion_01_slice66.npy',\n",
    " '000482_02_01_099_lesion_01_slice67.npy',\n",
    " '000482_02_01_099_lesion_01_slice68.npy',\n",
    " '000482_02_01_099_lesion_01_slice69.npy',\n",
    " '000482_02_01_099_lesion_01_slice70.npy',\n",
    " '000482_02_01_099_lesion_01_slice71.npy',\n",
    " '000482_02_01_099_lesion_01_slice72.npy',\n",
    " '000482_02_01_099_lesion_01_slice73.npy',\n",
    " '000482_02_01_099_lesion_01_slice74.npy',\n",
    " '000879_03_01_054_lesion_01_slice63.npy',\n",
    " '000879_03_01_054_lesion_01_slice64.npy',\n",
    " '000879_03_01_054_lesion_01_slice65.npy',\n",
    " '000879_03_01_054_lesion_01_slice66.npy',\n",
    " '000879_03_01_054_lesion_01_slice67.npy',\n",
    " '000879_03_01_054_lesion_01_slice68.npy',\n",
    " '000879_03_01_054_lesion_01_slice69.npy',\n",
    " '000879_03_01_054_lesion_01_slice70.npy',\n",
    " '000879_03_01_054_lesion_01_slice71.npy',\n",
    " '000879_03_01_054_lesion_01_slice72.npy']"
   ],
   "id": "4b1673ee8abd9f0f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# visualize data and model output\n",
    "from torchmetrics.segmentation import DiceScore\n",
    "\n",
    "dice = DiceScore(1)\n",
    "val_loader = DataLoader(val_dataset, batch_size=1, shuffle=True, num_workers=workers)\n",
    "\n",
    "res = []\n",
    "n = 0\n",
    "for i, data in enumerate(val_loader):\n",
    "    # if data['name'][0] != \"000738_01_01_075_lesion_01_slice62.npy\": #not in large_lesion_names:\n",
    "    #     continue\n",
    "\n",
    "    box_area_ratio = data['box_mask'].mean().item()\n",
    "\n",
    "    img = data['input'].squeeze()[0]\n",
    "    box_mask = data['input'].squeeze()[1]\n",
    "    out_raw = unet.model.to(device)(data['input'].to(device)).detach().cpu().squeeze()\n",
    "    out = out_raw.clone() > 0.5\n",
    "\n",
    "    gt = data['mask'].bool().squeeze()\n",
    "    pred = out.bool().squeeze()\n",
    "\n",
    "    # get metrics\n",
    "    tp = gt & pred\n",
    "    fp = ~gt & pred\n",
    "    fn = gt & ~pred\n",
    "\n",
    "    dice_score = dice(pred.unsqueeze(0), gt.unsqueeze(0))\n",
    "    vol_sim = 1 - abs(pred.sum() - gt.sum()) / gt.sum()\n",
    "\n",
    "    res.append({\"dice\": dice_score.item(), \"vs\": vol_sim.item(), \"area_ratio\": box_area_ratio})\n",
    "    if fp.sum() + fn.sum() > max(30, (0.3 * gt.sum())):\n",
    "    # if True:\n",
    "        # continue\n",
    "        print(f\"dice: {dice_score:.3f}, volume similarity: {vol_sim:.3f}\")\n",
    "        print(data['name'])\n",
    "        fig, ax = plt.subplots(1, 3, figsize=(6,2))\n",
    "        ax[0].imshow(img, vmin=0, vmax=1, cmap='gray')\n",
    "\n",
    "        ax[1].imshow(img, vmin=0, vmax=1, cmap='gray')\n",
    "        ax[1].imshow(out * tp, cmap=transparent_cmap(\"green\"), alpha=0.6)\n",
    "        ax[1].imshow(out * fp, cmap=transparent_cmap(\"red\"), alpha=0.6)\n",
    "        ax[1].imshow(fn, cmap=transparent_cmap(\"blueviolet\"), alpha=0.6)\n",
    "\n",
    "        ax[2].imshow(out_raw, vmin=0, vmax=1, cmap=\"summer_r\", alpha=1)\n",
    "        ax[2].imshow(box_mask, cmap=transparent_cmap(\"cyan\"), alpha=0.2)\n",
    "\n",
    "        [a.axis('off') for a in ax]\n",
    "        plt.show()\n",
    "        n += 1\n",
    "    #\n",
    "    # if n > 10:\n",
    "    #     break"
   ],
   "id": "534ad06ac9cabe1c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(res)\n",
    "df.describe().round(3).loc[['50%', 'mean']]"
   ],
   "id": "4e1ac6e7ce25c7dd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns"
   ],
   "id": "b3545675da6cc2e4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# get lesion stats\n",
    "val_loader = DataLoader(val_dataset, batch_size=1, shuffle=True, num_workers=workers)\n",
    "\n",
    "sizes = []\n",
    "boxes = []\n",
    "h_ratios = []\n",
    "w_ratios = []\n",
    "area_ratios = []\n",
    "for i, data in enumerate(val_loader):\n",
    "    size = data['original_size']\n",
    "    box = [x.item() for x in data['original_bbox']]\n",
    "\n",
    "    area_ratios.append(data['mask'][0].mean().item())\n",
    "    x0, y0, x1, y1 = get_seg_bbox(data['box_mask'][0])\n",
    "    w_ratios.append((x1 - x0) / 128)\n",
    "    h_ratios.append((y1 - y0) / 128)\n",
    "\n",
    "    sizes.append(size[0].item())\n",
    "    boxes.append(box)\n",
    "    # print(box)\n",
    "    # break\n",
    "\n",
    "df = pd.DataFrame(boxes, columns=[\"xmin\", \"ymin\", \"xmax\", \"ymax\"])\n",
    "\n",
    "df['width'] = df['xmax'] - df['xmin']\n",
    "df['height'] = df['ymax'] - df['ymin']\n",
    "\n",
    "df['width_ratio'] = w_ratios\n",
    "df['height_ratio'] = h_ratios\n",
    "df['box_area_ratio'] = df['width_ratio'] * df['height_ratio']\n",
    "df['area_ratio'] = area_ratios"
   ],
   "id": "193abc0141f74f99",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "sns.jointplot(\n",
    "    data=df, x=\"width_ratio\", y=\"height_ratio\", height=5,\n",
    "    size=df['box_area_ratio'].tolist(),\n",
    "    hue='box_area_ratio',\n",
    "    legend=None,\n",
    ");"
   ],
   "id": "63e88c1f81cbd91e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "sns.jointplot(\n",
    "    data=df, x=\"width_ratio\", y=\"height_ratio\", height=5,\n",
    "    size=df['box_area_ratio'].tolist(),\n",
    "    hue='box_area_ratio',\n",
    "    legend=None,\n",
    ");"
   ],
   "id": "2e29a5602d2ac888",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "sns.jointplot(\n",
    "    data=df, x=\"width_ratio\", y=\"height_ratio\", height=5,\n",
    "    size=df['box_area_ratio'].tolist(),\n",
    "    hue='box_area_ratio',\n",
    "    legend=None,\n",
    ");"
   ],
   "id": "5611d9273670c662",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "sns.jointplot(data=df, x=\"width\", y=\"height\", height=5,\n",
    "              size=df['area_ratio'].tolist(),\n",
    "              # hue='box_area_ratio'\n",
    "              );"
   ],
   "id": "850b812e577dc604",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ctseg-py3.12",
   "language": "python",
   "name": "ctseg-py3.12"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

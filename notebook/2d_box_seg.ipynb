{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Training a 2D bbox to 2D segmentation model\n",
    "---"
   ],
   "id": "7acbf8c49883ba50"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "id": "6c8827d5c971ef1f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from collections import Counter\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from evaluation.eval_utils import get_seg_bbox\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "import nrrd\n",
    "import SimpleITK as sitk\n",
    "from utils.plot import transparent_cmap"
   ],
   "id": "7b960d3bfd8b1693",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Dataset\n",
    "data_folder = Path(\"/media/liushifeng/KINGSTON/ULS Jan 2025/ULS23/novel_data/ULS23_DeepLesion3D\")\n",
    "seg_folder = data_folder / \"labels\"\n",
    "ct_folder = data_folder / \"images\"\n",
    "\n",
    "with open(data_folder / \"train.txt\", \"r\") as f:\n",
    "    train_names = [x.strip() for x in f.readlines()]\n",
    "with open(data_folder / \"val.txt\", \"r\") as f:\n",
    "    val_names = [x.strip() for x in f.readlines()]\n",
    "\n",
    "filenames = [x for x in os.listdir(seg_folder) if \".zip\" not in x]\n",
    "seg_paths = {x: seg_folder / x for x in filenames}\n",
    "ct_paths = {x: ct_folder / x for x in filenames}"
   ],
   "id": "c30e0214b5bbe9f3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "ignored_train_samples = [x.strip() for x in\n",
    "    \"\"\"\n",
    "    000148_04_01_034_lesion_01\n",
    "    003287_01_01_188_lesion_01\n",
    "    003931_01_01_078_lesion_01\n",
    "    000026_06_01_257_lesion_01\n",
    "    000346_01_01_085_lesion_01\n",
    "    000215_05_01_096_lesion_01\n",
    "    001354_04_02_305_lesion_01\n",
    "    001564_02_02_513_lesion_01\n",
    "    \"\"\".split(\"\\n\") if x.strip()]"
   ],
   "id": "cd4a56b7eb04c589",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# for plotting histograms\n",
    "bins = [int(x) for x in np.arange(-1000, 2001, 50)] + [2050] # Define HU bins\n",
    "hu_counter = Counter()  # Initialize the counter"
   ],
   "id": "fbc15bc7479b24ae",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "for every lesion, based on filename:\n",
    "- input\n",
    "    - crop (32X * 32Y)\n",
    "    - rectangle patch or border of the segment (32X * 32Y)\n",
    "    - full slice as context (fixed size e.g. 256 * 256)\n",
    "- output\n",
    "    - seg (32X * 32Y) **Blur for soft mask?**"
   ],
   "id": "6872350c925448ec"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "seg, _ = nrrd.read(\"/media/liushifeng/KINGSTON/ULS DL3D 2D dataset/masks/002779_01_01_183_lesion_01_slice61_seg\")",
   "id": "c47efa74517ceef7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from train_utils import crop_from_img\n",
    "\n",
    "output_folder = Path(\"/media/liushifeng/KINGSTON/ULS DL3D 2D dataset/\")\n",
    "\n",
    "plot = 0\n",
    "save = 0\n",
    "\n",
    "for filename in list(seg_paths.keys()):\n",
    "    if filename.split(\".\")[0] in ignored_train_samples:\n",
    "        print(\"skipped:\", filename.split(\".\")[0])\n",
    "        continue\n",
    "\n",
    "    lesion_name = filename.split(\".\")[0]\n",
    "\n",
    "    # load arrays\n",
    "    ct = sitk.ReadImage(ct_paths[filename])\n",
    "    ct_array = sitk.GetArrayFromImage(ct)\n",
    "    seg = sitk.ReadImage(seg_paths[filename])\n",
    "    seg_array = sitk.GetArrayFromImage(seg)\n",
    "\n",
    "    # get slices where there are segmentations\n",
    "    seg_slice_indices = np.where(seg_array.any(axis=(1,2)) > 0)[0]\n",
    "\n",
    "    for i in seg_slice_indices:\n",
    "        ct_slice = ct_array[i]\n",
    "        seg_slice = seg_array[i]\n",
    "\n",
    "        crop_bbox = get_seg_bbox(seg_slice)\n",
    "\n",
    "        if save:\n",
    "            print(f\"saving {lesion_name}_slice{i}\")\n",
    "            # train_or_val = \"train\" if lesion_name in train_names else \"val\"\n",
    "            # save_folder = output_folder / train_or_val\n",
    "            # save_folder.mkdir(parents=True, exist_ok=True)\n",
    "            np.save(str(output_folder / \"images\" / f\"{lesion_name}_slice{i}.npy\"), ct_slice)\n",
    "            # nrrd.write(str(output_folder / \"slices\" / f\"{lesion_name}_slice{i}_seg\"), seg_slice)\n",
    "\n",
    "        if plot:\n",
    "            vmin, vmax = -200, 200\n",
    "            plt.imshow(ct_slice, vmin=vmin, vmax=vmax, cmap='gray')\n",
    "            plt.show()\n",
    "            plt.imshow(seg_slice)\n",
    "            plt.show()\n",
    "\n",
    "            # crops areas for plotting\n",
    "            margin = 2\n",
    "            ct_crop = crop_from_img(ct_slice, crop_bbox, margin, AIR_VALUE)\n",
    "            seg_crop = crop_from_img(seg_slice, crop_bbox, margin, 0)\n",
    "\n",
    "        # hu_counter.update(np.digitize(ct_crop.flatten(), bins))\n",
    "        # hu_counter.update(np.digitize(ct_crop[seg_crop == 1], bins))"
   ],
   "id": "a79388468058c798",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# if save:\n",
    "#     # save training data set\n",
    "#     train_or_val = \"train\" if lesion_name in train_names else \"val\"\n",
    "#     save_folder = output_folder / train_or_val\n",
    "#     save_folder.mkdir(parents=True, exist_ok=True)\n",
    "#\n",
    "#     np.save(save_folder / f\"{lesion_name}_slice{i}_crop\", np.array(ct_crop, dtype=np.int16))\n",
    "#     np.save(save_folder / f\"{lesion_name}_slice{i}_cropseg\", np.array(seg_crop, dtype=np.uint8))\n",
    "#     np.save(save_folder / f\"{lesion_name}_slice{i}_slice\", np.array(ct_slice, dtype=np.int16))\n",
    "#\n",
    "# if plot:\n",
    "#     _, axes = plt.subplots(1, 2, figsize=(4, 2))\n",
    "#\n",
    "#     # plot the crop and segment\n",
    "#     vmin, vmax = -200, 200\n",
    "#     axes[0].imshow(ct_crop, vmin=vmin, vmax=vmax, cmap='gray')\n",
    "#     axes[1].imshow(ct_crop, vmin=vmin, vmax=vmax, cmap='gray')\n",
    "#     axes[1].imshow(seg_crop, cmap=transparent_cmap(\"blue\"), alpha=0.4)\n",
    "#     for ax in axes:\n",
    "#         ax.axis(\"off\")\n",
    "#     plt.show()\n",
    "#\n",
    "#     # plot the entire slice\n",
    "#     _, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "#     axes[0].imshow(ct_slice, cmap='gray')\n",
    "#     axes[1].imshow(ct_slice, cmap='gray')\n",
    "#     axes[1].imshow(seg_slice, cmap=transparent_cmap(\"blue\"), alpha=0.4)\n",
    "#     for ax in axes:\n",
    "#         ax.axis(\"off\")\n",
    "#     plt.show()"
   ],
   "id": "bea30ff75a18099a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plt.figure(figsize=(6,2.5));\n",
    "plt.bar([bins[int(x)] for x in hu_counter.keys()], hu_counter.values(), width=50);"
   ],
   "id": "abe8c51a273ef04",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plt.figure(figsize=(6,2.5));\n",
    "plt.bar([bins[int(x)] for x in hu_counter.keys()], hu_counter.values(), width=50);"
   ],
   "id": "c40d9fd6524f4c7a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plt.imshow(ct_slice, cmap='gray'); plt.axis(\"off\");\n",
    "plt.imshow(seg_slice, cmap='jet', alpha=0.5); plt.axis(\"off\");"
   ],
   "id": "ec58bff2499ee0bb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Load data",
   "id": "ca184f5857d77770"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "data_dir = Path(\"/media/liushifeng/KINGSTON/ULS DL3D 2D dataset\")",
   "id": "fb4fa43161882564",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from dataset import SegmentationDataset\n",
    "\n",
    "image_dir = data_dir / \"images\"\n",
    "label_dir = data_dir / \"masks\"\n",
    "all_images = sorted(os.listdir(image_dir))\n",
    "\n",
    "# random.shuffle(all_images)  # Shuffle before splitting\n",
    "# val_size = int(0.25 * len(all_images))\n",
    "# val_images = all_images[:val_size]\n",
    "# train_images = all_images[val_size:]\n",
    "\n",
    "val_images = [x for x in all_images if x.split(\"_slice\")[0] in val_names]\n",
    "train_images = [x for x in all_images if x.split(\"_slice\")[0] in train_names]"
   ],
   "id": "37f02184712b935d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from transforms import train_transform, val_transform\n",
    "\n",
    "image_names = None\n",
    "batch_size = 1\n",
    "workers = 20\n",
    "train_dataset = SegmentationDataset(image_dir, label_dir, train_images, train_transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=workers)\n",
    "\n",
    "val_dataset = SegmentationDataset(image_dir, label_dir, val_images, val_transform)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=workers)\n",
    "\n",
    "# Visualizing data loader\n",
    "data = next(iter(val_loader))\n",
    "plt.figure(figsize=(3,3))\n",
    "plt.imshow(data['image'].squeeze(), cmap='gray')\n",
    "plt.imshow(data['mask'].squeeze(), cmap=transparent_cmap(\"blue\"), alpha=0.5)\n",
    "plt.imshow(data['box_mask'].squeeze(), cmap='Greens', alpha=0.3)\n",
    "# plt.axis('off');\n",
    "plt.show()"
   ],
   "id": "f005c29dd4e4cdf7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Train Model",
   "id": "956e15960762c2b5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=SyntaxWarning)\n",
    "import torch\n",
    "import lightning as L\n",
    "from lightning.pytorch.callbacks import EarlyStopping\n",
    "\n",
    "torch.set_float32_matmul_precision('medium')\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ],
   "id": "7a149f50f5d1f802",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from model import UNet\n",
    "\n",
    "unet = UNet()\n",
    "early_stopping = EarlyStopping('val_loss', verbose=True)\n",
    "trainer = L.Trainer(\n",
    "    accumulate_grad_batches=32,\n",
    "    max_epochs=20,\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "trainer.fit(unet, train_loader, val_loader)"
   ],
   "id": "18945fe911f91775",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "trainer.early_stopping_callback.stopped_epoch",
   "id": "d0706e994bb4f694",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# visualize data and model output\n",
    "from torchmetrics.segmentation import DiceScore\n",
    "\n",
    "dice = DiceScore(1)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True, num_workers=workers)\n",
    "\n",
    "res = []\n",
    "n = 0\n",
    "for i, data in tqdm(enumerate(val_loader)):\n",
    "# data = next(iter(val_loader))\n",
    "    img = data['input'].squeeze()[0]\n",
    "    out_raw = unet.model.to(device)(data['input'].to(device)).detach().cpu().squeeze()\n",
    "    out = out_raw.clone()\n",
    "    out[out < 0.5] = 0\n",
    "\n",
    "    gt = data['mask'].bool().squeeze()\n",
    "    pred = out.bool().squeeze()\n",
    "\n",
    "    tp = gt & pred\n",
    "    fp = ~gt & pred\n",
    "    fn = gt & ~pred\n",
    "\n",
    "    dice_score = dice(pred.unsqueeze(0), gt.unsqueeze(0))\n",
    "    dice_scores.append(dice_score.item())\n",
    "\n",
    "    vol_sim = 1 - abs(pred.sum() - gt.sum()) / gt.sum()\n",
    "    vol_scores.append(vol_sim.item())\n",
    "\n",
    "    res.append({\"dice\": dice_score.item(), \"vs\": vol_sim.item()})\n",
    "    # if fp.sum() + fn.sum() > max(70, (0.6 * tp.sum())):\n",
    "    if False:\n",
    "        print(dice_score)\n",
    "        fig, ax = plt.subplots(1, 3, figsize=(6,2))\n",
    "        ax[0].imshow(img, cmap='gray')\n",
    "\n",
    "        ax[1].imshow(img, cmap='gray')\n",
    "        ax[1].imshow(out * tp, cmap=transparent_cmap(\"green\"), alpha=0.4)\n",
    "        ax[1].imshow(out * fp, cmap=transparent_cmap(\"red\"), alpha=0.4)\n",
    "        ax[1].imshow(fn, cmap=transparent_cmap(\"blueviolet\"), alpha=0.4)\n",
    "\n",
    "        ax[2].imshow(out, vmin=0, vmax=1, cmap=\"summer_r\", alpha=1)\n",
    "\n",
    "        [a.axis('off') for a in ax]\n",
    "        plt.show()\n",
    "        n += 1\n",
    "\n",
    "    if n > 1e10:\n",
    "        break\n"
   ],
   "id": "534ad06ac9cabe1c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame(res).describe()"
   ],
   "id": "730fddcb6c658b85",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ctseg-py3.12",
   "language": "python",
   "name": "ctseg-py3.12"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
